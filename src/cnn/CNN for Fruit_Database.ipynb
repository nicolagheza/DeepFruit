{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pickle\n",
    "\n",
    "NAME = \"Fruit_Database-CNN-256\"\n",
    "\n",
    "no_of_classes = 15\n",
    "\n",
    "pickle_in = open(\"C:/Users/nicol/Code/DeepFruit/Fruit_Database/X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"C:/Users/nicol/Code/DeepFruit/Fruit_Database/y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "y = np_utils.to_categorical(y,no_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 16)      80        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 256)         131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               345750    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                2265      \n",
      "=================================================================\n",
      "Total params: 522,655\n",
      "Trainable params: 522,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29475 samples, validate on 12633 samples\n",
      "Epoch 1/100\n",
      "29475/29475 [==============================] - 62s 2ms/step - loss: 1.5752 - acc: 0.4883 - val_loss: 0.7793 - val_acc: 0.7563\n",
      "Epoch 2/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.7955 - acc: 0.7401 - val_loss: 0.5465 - val_acc: 0.8233\n",
      "Epoch 3/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.6238 - acc: 0.7919 - val_loss: 0.4640 - val_acc: 0.8474\n",
      "Epoch 4/100\n",
      "29475/29475 [==============================] - 55s 2ms/step - loss: 0.5230 - acc: 0.8254 - val_loss: 0.4211 - val_acc: 0.8555\n",
      "Epoch 5/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.4511 - acc: 0.8481 - val_loss: 0.3684 - val_acc: 0.8812\n",
      "Epoch 6/100\n",
      "29475/29475 [==============================] - 55s 2ms/step - loss: 0.3928 - acc: 0.8696 - val_loss: 0.3674 - val_acc: 0.8771\n",
      "Epoch 7/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.3339 - acc: 0.8877 - val_loss: 0.3015 - val_acc: 0.8990\n",
      "Epoch 8/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.3037 - acc: 0.8960 - val_loss: 0.3119 - val_acc: 0.8976\n",
      "Epoch 9/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.2656 - acc: 0.9102 - val_loss: 0.2384 - val_acc: 0.9207\n",
      "Epoch 10/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.2378 - acc: 0.9196 - val_loss: 0.2326 - val_acc: 0.9254\n",
      "Epoch 11/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.2106 - acc: 0.9270 - val_loss: 0.2366 - val_acc: 0.9226\n",
      "Epoch 12/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.1865 - acc: 0.9384 - val_loss: 0.2231 - val_acc: 0.9271\n",
      "Epoch 13/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.1796 - acc: 0.9389 - val_loss: 0.2120 - val_acc: 0.9310\n",
      "Epoch 14/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.1598 - acc: 0.9469 - val_loss: 0.1978 - val_acc: 0.9383\n",
      "Epoch 15/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.1534 - acc: 0.9475 - val_loss: 0.1878 - val_acc: 0.9406\n",
      "Epoch 16/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.1462 - acc: 0.9519 - val_loss: 0.1747 - val_acc: 0.9464\n",
      "Epoch 17/100\n",
      "29475/29475 [==============================] - 58s 2ms/step - loss: 0.1292 - acc: 0.9572 - val_loss: 0.1773 - val_acc: 0.9428\n",
      "Epoch 18/100\n",
      "29475/29475 [==============================] - 60s 2ms/step - loss: 0.1195 - acc: 0.9604 - val_loss: 0.2059 - val_acc: 0.9404\n",
      "Epoch 19/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.1195 - acc: 0.9597 - val_loss: 0.1929 - val_acc: 0.9427\n",
      "Epoch 20/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.1066 - acc: 0.9644 - val_loss: 0.1928 - val_acc: 0.9422\n",
      "Epoch 21/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.1061 - acc: 0.9645 - val_loss: 0.1944 - val_acc: 0.9424\n",
      "Epoch 22/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.1033 - acc: 0.9668 - val_loss: 0.2082 - val_acc: 0.9379\n",
      "Epoch 23/100\n",
      "29475/29475 [==============================] - 60s 2ms/step - loss: 0.1060 - acc: 0.9647 - val_loss: 0.1732 - val_acc: 0.9460\n",
      "Epoch 24/100\n",
      "29475/29475 [==============================] - 58s 2ms/step - loss: 0.0883 - acc: 0.9707 - val_loss: 0.1937 - val_acc: 0.9462\n",
      "Epoch 25/100\n",
      "29475/29475 [==============================] - 60s 2ms/step - loss: 0.0945 - acc: 0.9688 - val_loss: 0.1921 - val_acc: 0.9481\n",
      "Epoch 26/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0948 - acc: 0.9686 - val_loss: 0.1607 - val_acc: 0.9513\n",
      "Epoch 27/100\n",
      "29475/29475 [==============================] - 62s 2ms/step - loss: 0.0801 - acc: 0.9738 - val_loss: 0.1567 - val_acc: 0.9534\n",
      "Epoch 28/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.0884 - acc: 0.9722 - val_loss: 0.1805 - val_acc: 0.9482\n",
      "Epoch 29/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0759 - acc: 0.9748 - val_loss: 0.1822 - val_acc: 0.9501\n",
      "Epoch 30/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.0767 - acc: 0.9754 - val_loss: 0.1569 - val_acc: 0.9551\n",
      "Epoch 31/100\n",
      "29475/29475 [==============================] - 64s 2ms/step - loss: 0.0787 - acc: 0.9748 - val_loss: 0.2095 - val_acc: 0.9428\n",
      "Epoch 32/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.0720 - acc: 0.9766 - val_loss: 0.1480 - val_acc: 0.9577\n",
      "Epoch 33/100\n",
      "29475/29475 [==============================] - 60s 2ms/step - loss: 0.0783 - acc: 0.9756 - val_loss: 0.1643 - val_acc: 0.9524\n",
      "Epoch 34/100\n",
      "29475/29475 [==============================] - 62s 2ms/step - loss: 0.0653 - acc: 0.9783 - val_loss: 0.1715 - val_acc: 0.9546\n",
      "Epoch 35/100\n",
      "29475/29475 [==============================] - 62s 2ms/step - loss: 0.0731 - acc: 0.9759 - val_loss: 0.1777 - val_acc: 0.9504\n",
      "Epoch 36/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0770 - acc: 0.9751 - val_loss: 0.1746 - val_acc: 0.9535\n",
      "Epoch 37/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0585 - acc: 0.9815 - val_loss: 0.1608 - val_acc: 0.9542\n",
      "Epoch 38/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0624 - acc: 0.9806 - val_loss: 0.1682 - val_acc: 0.9544\n",
      "Epoch 39/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0689 - acc: 0.9781 - val_loss: 0.1661 - val_acc: 0.9548\n",
      "Epoch 40/100\n",
      "29475/29475 [==============================] - 65s 2ms/step - loss: 0.0643 - acc: 0.9797 - val_loss: 0.1518 - val_acc: 0.9584\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0704 - acc: 0.9785 - val_loss: 0.1970 - val_acc: 0.9501\n",
      "Epoch 42/100\n",
      "29475/29475 [==============================] - 92s 3ms/step - loss: 0.0612 - acc: 0.9812 - val_loss: 0.1589 - val_acc: 0.9563\n",
      "Epoch 43/100\n",
      "29475/29475 [==============================] - 58s 2ms/step - loss: 0.0595 - acc: 0.9802 - val_loss: 0.1798 - val_acc: 0.9536\n",
      "Epoch 44/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0635 - acc: 0.9804 - val_loss: 0.1557 - val_acc: 0.9575\n",
      "Epoch 45/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0652 - acc: 0.9792 - val_loss: 0.1588 - val_acc: 0.9564\n",
      "Epoch 46/100\n",
      "29475/29475 [==============================] - 58s 2ms/step - loss: 0.0593 - acc: 0.9821 - val_loss: 0.1491 - val_acc: 0.9610\n",
      "Epoch 47/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.0611 - acc: 0.9811 - val_loss: 0.1526 - val_acc: 0.9567\n",
      "Epoch 48/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.0554 - acc: 0.9811 - val_loss: 0.1426 - val_acc: 0.9594\n",
      "Epoch 49/100\n",
      "29475/29475 [==============================] - 60s 2ms/step - loss: 0.0552 - acc: 0.9822 - val_loss: 0.1662 - val_acc: 0.9553\n",
      "Epoch 50/100\n",
      "29475/29475 [==============================] - 61s 2ms/step - loss: 0.0566 - acc: 0.9825 - val_loss: 0.1533 - val_acc: 0.9580\n",
      "Epoch 51/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.0609 - acc: 0.9825 - val_loss: 0.1836 - val_acc: 0.9522\n",
      "Epoch 52/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0532 - acc: 0.9835 - val_loss: 0.1707 - val_acc: 0.9564\n",
      "Epoch 53/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0466 - acc: 0.9844 - val_loss: 0.2195 - val_acc: 0.9510\n",
      "Epoch 54/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0562 - acc: 0.9828 - val_loss: 0.2008 - val_acc: 0.9499\n",
      "Epoch 55/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0539 - acc: 0.9827 - val_loss: 0.2226 - val_acc: 0.9503\n",
      "Epoch 56/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0563 - acc: 0.9827 - val_loss: 0.1730 - val_acc: 0.9535\n",
      "Epoch 57/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0511 - acc: 0.9841 - val_loss: 0.1616 - val_acc: 0.9586\n",
      "Epoch 58/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0489 - acc: 0.9848 - val_loss: 0.1937 - val_acc: 0.9540\n",
      "Epoch 59/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0578 - acc: 0.9819 - val_loss: 0.1545 - val_acc: 0.9633\n",
      "Epoch 60/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.0515 - acc: 0.9842 - val_loss: 0.1722 - val_acc: 0.9575\n",
      "Epoch 61/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.0506 - acc: 0.9845 - val_loss: 0.1604 - val_acc: 0.9596\n",
      "Epoch 62/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0510 - acc: 0.9848 - val_loss: 0.1777 - val_acc: 0.9574\n",
      "Epoch 63/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0455 - acc: 0.9853 - val_loss: 0.2399 - val_acc: 0.9477\n",
      "Epoch 64/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0611 - acc: 0.9831 - val_loss: 0.1584 - val_acc: 0.9599\n",
      "Epoch 65/100\n",
      "29475/29475 [==============================] - 57s 2ms/step - loss: 0.0496 - acc: 0.9854 - val_loss: 0.1717 - val_acc: 0.9587\n",
      "Epoch 66/100\n",
      "29475/29475 [==============================] - 55s 2ms/step - loss: 0.0442 - acc: 0.9863 - val_loss: 0.1468 - val_acc: 0.9622\n",
      "Epoch 67/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0520 - acc: 0.9848 - val_loss: 0.1920 - val_acc: 0.9584\n",
      "Epoch 68/100\n",
      "29475/29475 [==============================] - 55s 2ms/step - loss: 0.0519 - acc: 0.9849 - val_loss: 0.1665 - val_acc: 0.9616\n",
      "Epoch 69/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0434 - acc: 0.9868 - val_loss: 0.2152 - val_acc: 0.9500\n",
      "Epoch 70/100\n",
      "29475/29475 [==============================] - 59s 2ms/step - loss: 0.0483 - acc: 0.9856 - val_loss: 0.1632 - val_acc: 0.9618\n",
      "Epoch 71/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0478 - acc: 0.9863 - val_loss: 0.1568 - val_acc: 0.9601\n",
      "Epoch 72/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0534 - acc: 0.9839 - val_loss: 0.1414 - val_acc: 0.9645\n",
      "Epoch 73/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0411 - acc: 0.9885 - val_loss: 0.1664 - val_acc: 0.9612\n",
      "Epoch 74/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0603 - acc: 0.9832 - val_loss: 0.1570 - val_acc: 0.9608\n",
      "Epoch 75/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0427 - acc: 0.9871 - val_loss: 0.2134 - val_acc: 0.9535\n",
      "Epoch 76/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0578 - acc: 0.9850 - val_loss: 0.1523 - val_acc: 0.9632\n",
      "Epoch 77/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0458 - acc: 0.9861 - val_loss: 0.2081 - val_acc: 0.9528\n",
      "Epoch 78/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0495 - acc: 0.9854 - val_loss: 0.1701 - val_acc: 0.9598\n",
      "Epoch 79/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0499 - acc: 0.9856 - val_loss: 0.1597 - val_acc: 0.9641\n",
      "Epoch 80/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0472 - acc: 0.9864 - val_loss: 0.1541 - val_acc: 0.9634\n",
      "Epoch 81/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0488 - acc: 0.9854 - val_loss: 0.1444 - val_acc: 0.9642\n",
      "Epoch 82/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0475 - acc: 0.9861 - val_loss: 0.1679 - val_acc: 0.9594\n",
      "Epoch 83/100\n",
      "29475/29475 [==============================] - 54s 2ms/step - loss: 0.0528 - acc: 0.9855 - val_loss: 0.1522 - val_acc: 0.9643\n",
      "Epoch 84/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0387 - acc: 0.9892 - val_loss: 0.1745 - val_acc: 0.9600\n",
      "Epoch 85/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0421 - acc: 0.9887 - val_loss: 0.1811 - val_acc: 0.9603\n",
      "Epoch 86/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0513 - acc: 0.9860 - val_loss: 0.1700 - val_acc: 0.9610\n",
      "Epoch 87/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0451 - acc: 0.9870 - val_loss: 0.1766 - val_acc: 0.9592\n",
      "Epoch 88/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0372 - acc: 0.9888 - val_loss: 0.1796 - val_acc: 0.9638\n",
      "Epoch 89/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0480 - acc: 0.9866 - val_loss: 0.1598 - val_acc: 0.9617\n",
      "Epoch 90/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0346 - acc: 0.9906 - val_loss: 0.1835 - val_acc: 0.9604\n",
      "Epoch 91/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0512 - acc: 0.9865 - val_loss: 0.1905 - val_acc: 0.9592\n",
      "Epoch 92/100\n",
      "29475/29475 [==============================] - 53s 2ms/step - loss: 0.0483 - acc: 0.9864 - val_loss: 0.1601 - val_acc: 0.9614\n",
      "Epoch 93/100\n",
      "29475/29475 [==============================] - 55s 2ms/step - loss: 0.0383 - acc: 0.9897 - val_loss: 0.1939 - val_acc: 0.9581\n",
      "Epoch 94/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0417 - acc: 0.9885 - val_loss: 0.1651 - val_acc: 0.9638\n",
      "Epoch 95/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0487 - acc: 0.9866 - val_loss: 0.1513 - val_acc: 0.9645\n",
      "Epoch 96/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0475 - acc: 0.9877 - val_loss: 0.1711 - val_acc: 0.9609\n",
      "Epoch 97/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0366 - acc: 0.9894 - val_loss: 0.1587 - val_acc: 0.9651\n",
      "Epoch 98/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0522 - acc: 0.9865 - val_loss: 0.1794 - val_acc: 0.9601\n",
      "Epoch 99/100\n",
      "29475/29475 [==============================] - 56s 2ms/step - loss: 0.0407 - acc: 0.9883 - val_loss: 0.1605 - val_acc: 0.9645\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29475/29475 [==============================] - 55s 2ms/step - loss: 0.0404 - acc: 0.9892 - val_loss: 0.1891 - val_acc: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2008a0806a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,1),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(15,activation = 'softmax'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=100, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
